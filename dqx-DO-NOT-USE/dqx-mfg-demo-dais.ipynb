{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ae98d7f-ef12-4108-b543-10e305e908ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DAIS 2025 DQX Demo Session \n",
    "This notebook illustrates example usage of DQX for a fictional Manufacturing Company \"Machina Metrics\". <br>\n",
    "Watch **DAIS Demo Session Recording** that showcases this demo: https://www.youtube.com/watch?v=e5Qvx_gnxTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "759da186-2d00-4f53-95ad-075b386eccce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h1>\n",
    "MachinaMetrics - A Manufacturing Company\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e811e0b-5d3a-4535-b35d-332dd1701fdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Aspirations - Proactive Machine Maintenance\n",
    "\n",
    "MachinaMetrics is a leading-edge manufacturing company whose CTO is spearheading the adoption of an AI-driven predictive maintenance solution. By harnessing real-time machine status data and historical maintenance schedules, this technology will proactively forecast service needs, minimize unplanned downtime, and optimize maintenance cycles. The result is a significant reduction in operational costs, extended equipment lifespan, and maximized production efficiency-positioning MachinaMetrics as an industry innovator in smart manufacturing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00f001e-5af6-4ab6-8fc9-110fd7ce2f4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DQX - The Data Quality Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b81302b-3546-46b3-a1ab-ffaa9b9ab6e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DQX options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a90d529-af7e-4852-a117-ae866985a0b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "| Type | Description | Features|\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Installation| Deploy as a Library | Deploy as workspace tool \n",
    "| Usage | Use in Spark Dataframes| Use with DLT|\n",
    "| Quality Rules| Define as YAML| Define as Code|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a90dc6-1186-4694-bef2-24c9836ae7ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DQX in Lakehouse Architecture\n",
    "\n",
    "\n",
    "![dqx-in-lake.png](./images/dqx-in-lake.png \"dqx-in-lake.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b987a25c-adf8-4ee8-ba2c-810c8d1efc11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DQX - Install as Library <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1a5d9b-f887-4825-b588-9f3f7887ffc4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install DQX Library"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87296676-f3ea-4d82-b1e5-3bed3d71efbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea9cbbd6-8761-4b65-ae6e-03ba34320d44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903b8696-9c5f-4a33-8531-6a1332b64fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "workspace_root_path = os.getcwd()\n",
    "quality_rules_path = f\"{workspace_root_path}/quality_rules\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff9f7d2a-cc64-4225-873a-e990bbdf63b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sample Data Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "704abe3f-802d-4ce2-9b65-95d63ac3afad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set Catalog and Schema for Demo Dataset"
    }
   },
   "outputs": [],
   "source": [
    "default_database = \"main\"\n",
    "default_schema_name = \"default\"\n",
    "\n",
    "dbutils.widgets.text(\"demo_database\", default_database, \"Catalog Name\")\n",
    "dbutils.widgets.text(\"demo_schema\", default_schema_name, \"Schema Name\")\n",
    "\n",
    "database = dbutils.widgets.get(\"demo_database\")\n",
    "schema = dbutils.widgets.get(\"demo_schema\")\n",
    "\n",
    "print(f\"Selected Catalog for Demo Dataset: {database}\")\n",
    "print(f\"Selected Schema for Demo Dataset: {schema}\")\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {database}\")\n",
    "spark.sql(f\"USE CATALOG {database}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")\n",
    "spark.sql(f\"USE SCHEMA {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7cedcc17-3aaa-4f93-a193-3c406c3e942d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate Demo Sensor Datasets"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "import delta\n",
    "\n",
    "sensor_table = f\"{database}.{schema}.sensor_data\"\n",
    "\n",
    "if spark.catalog.tableExists(sensor_table) and spark.table(sensor_table).count() > 0:\n",
    "    print(\n",
    "        f\"Table {sensor_table} already exists with demo data. Skipping data generation\"\n",
    "    )\n",
    "else:\n",
    "    # 1. Enhanced Sensor Data with ingest_date and multiple rows per ingest_date\n",
    "    sensor_schema = StructType(\n",
    "        [\n",
    "            StructField(\"sensor_id\", StringType(), False),\n",
    "            StructField(\"machine_id\", StringType(), True),  # Allow null values\n",
    "            StructField(\"sensor_type\", StringType(), False),\n",
    "            StructField(\"reading_value\", DoubleType(), True),\n",
    "            StructField(\"reading_timestamp\", TimestampType(), True),\n",
    "            StructField(\"calibration_date\", DateType(), True),\n",
    "            StructField(\"battery_level\", IntegerType(), True),\n",
    "            StructField(\"facility_zone\", StringType(), True),\n",
    "            StructField(\"is_active\", BooleanType(), True),\n",
    "            StructField(\"firmware_version\", StringType(), True),\n",
    "            StructField(\"ingest_date\", DateType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sensor_data = [\n",
    "        # Ingest date 2025-04-28\n",
    "        (\n",
    "            \"SEN-001\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            72.4,\n",
    "            datetime.strptime(\"2025-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN-002\",\n",
    "            \"MCH-001\",\n",
    "            \"pressure\",\n",
    "            2.1,\n",
    "            datetime.strptime(\"2025-04-28 14:32:05\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-03-15\", \"%Y-%m-%d\").date(),\n",
    "            45,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v1.9.4\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN-003\",\n",
    "            \"MCH-002\",\n",
    "            \"vibration\",\n",
    "            0.02,\n",
    "            datetime.strptime(\"2025-04-28 14:32:10\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            None,\n",
    "            92,\n",
    "            \"Zone-B\",\n",
    "            False,\n",
    "            \"v3.0.0\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),  # Invalid calibration\n",
    "        # Ingest date 2025-04-29\n",
    "        (\n",
    "            \"SEN-001\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            73.5,\n",
    "            datetime.strptime(\"2025-04-29 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            80,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN-002\",\n",
    "            \"MCH-001\",\n",
    "            \"pressure\",\n",
    "            2.3,\n",
    "            datetime.strptime(\"2025-04-29 14:32:05\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-03-15\", \"%Y-%m-%d\").date(),\n",
    "            50,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v1.9.4\",\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN-004\",\n",
    "            None,\n",
    "            \"temperature\",\n",
    "            74.5,\n",
    "            datetime.strptime(\"2025-04-29 14:32:15\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-15\", \"%Y-%m-%d\").date(),\n",
    "            10,\n",
    "            \"Zone-C\",\n",
    "            True,\n",
    "            \"invalid_ver\",\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "        ),  # Multiple issues\n",
    "        # Ingest date 2025-04-30\n",
    "        (\n",
    "            \"SEN-001\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            74.0,\n",
    "            datetime.strptime(\"2025-04-30 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            75,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN-003\",\n",
    "            \"MCH-002\",\n",
    "            \"vibration\",\n",
    "            0.03,\n",
    "            datetime.strptime(\"2025-04-30 14:32:10\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            None,\n",
    "            90,\n",
    "            \"Zone-B\",\n",
    "            False,\n",
    "            \"v3.0.0\",\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Bad Data Insertion\n",
    "        # Sensor is empty\n",
    "        (\n",
    "            \"\",\n",
    "            \"MCH-002\",\n",
    "            \"vibration\",\n",
    "            0.03,\n",
    "            datetime.strptime(\"2025-04-30 14:32:10\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            None,\n",
    "            90,\n",
    "            \"Zone-B\",\n",
    "            False,\n",
    "            \"v3.0.0\",\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Machine_id is empty\n",
    "        (\n",
    "            \"SEN-001\",\n",
    "            \"\",\n",
    "            \"temperature\",\n",
    "            72.4,\n",
    "            datetime.strptime(\"2025-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Invalid Temperature\n",
    "        (\n",
    "            \"SEN-001\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            735,\n",
    "            datetime.strptime(\"2025-04-29 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            80,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Sensor regex pattern is wrong\n",
    "        (\n",
    "            \"SEN002\",\n",
    "            \"MCH-002\",\n",
    "            \"vibration\",\n",
    "            0.03,\n",
    "            datetime.strptime(\"2025-04-30 14:32:10\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            None,\n",
    "            90,\n",
    "            \"Zone-B\",\n",
    "            False,\n",
    "            \"v3.0.0\",\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN001\",\n",
    "            \"\",\n",
    "            \"temperature\",\n",
    "            72.4,\n",
    "            datetime.strptime(\"2025-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Reading TS in future\n",
    "        (\n",
    "            \"SEN-001\",\n",
    "            \"\",\n",
    "            \"temperature\",\n",
    "            72.4,\n",
    "            datetime.strptime(\"2026-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN-002\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            735,\n",
    "            datetime.strptime(\"2026-04-29 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            80,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Invalid Temperature\n",
    "        (\n",
    "            \"SEN-003\",\n",
    "            \"MCH-001\",\n",
    "            \"vibration\",\n",
    "            0.03,\n",
    "            datetime.strptime(\"2025-04-30 14:32:10\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            None,\n",
    "            90,\n",
    "            \"Zone-B\",\n",
    "            False,\n",
    "            \"v3.0.0\",\n",
    "            datetime.strptime(\"2025-05-01\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"SEN-004\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            15000.0,\n",
    "            datetime.strptime(\"2025-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Invalid wrong sensor pattern and ts in future\n",
    "        (\n",
    "            \"SE003\",\n",
    "            \"MCH-001\",\n",
    "            \"vibration\",\n",
    "            0.03,\n",
    "            datetime.strptime(\"2026-04-30 14:32:10\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            None,\n",
    "            90,\n",
    "            \"Zone-B\",\n",
    "            False,\n",
    "            \"v3.0.0\",\n",
    "            datetime.strptime(\"2025-05-01\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Invalid Temperature and wrong sensor pattern\n",
    "        (\n",
    "            \"SEN004\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            724,\n",
    "            datetime.strptime(\"2025-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Invalid Firmware Version and wrong sensor pattern\n",
    "        (\n",
    "            \"SEN004\",\n",
    "            \"MCH-001\",\n",
    "            \"temperature\",\n",
    "            724,\n",
    "            datetime.strptime(\"2025-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"b2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Machine ID regex pattern is wrong\n",
    "        (\n",
    "            \"SEN-002\",\n",
    "            \"MCH2\",\n",
    "            \"vibration\",\n",
    "            0.03,\n",
    "            datetime.strptime(\"2025-04-30 14:32:10\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            None,\n",
    "            90,\n",
    "            \"Zone-B\",\n",
    "            False,\n",
    "            \"v3.0.0\",\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"\",\n",
    "            \"MCH2\",\n",
    "            \"temperature\",\n",
    "            72.4,\n",
    "            datetime.strptime(\"2025-04-28 14:32:00\", \"%Y-%m-%d %H:%M:%S\"),\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            85,\n",
    "            \"Zone-A\",\n",
    "            True,\n",
    "            \"v2.3.1\",\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    sensor_df = spark.createDataFrame(sensor_data, schema=sensor_schema)\n",
    "    sensor_df.write.mode(\"overwrite\").saveAsTable(sensor_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "76d84d41-956a-4e9d-abe0-4a777bc2c977",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Generate Demo Maintenance Datasets"
    }
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "maintenance_table = f\"{database}.{schema}.maintenance_data\"\n",
    "\n",
    "if (\n",
    "    spark.catalog.tableExists(maintenance_table)\n",
    "    and spark.table(maintenance_table).count() > 0\n",
    "):\n",
    "    print(\n",
    "        f\"Table {maintenance_table} already exists with demo data. Skipping data generation\"\n",
    "    )\n",
    "else:\n",
    "    # 2. Enhanced Maintenance Data with ingest_date and multiple rows per ingest_date\n",
    "    maintenance_schema = StructType(\n",
    "        [\n",
    "            StructField(\"maintenance_id\", StringType(), False),\n",
    "            StructField(\"machine_id\", StringType(), False),\n",
    "            StructField(\"maintenance_type\", StringType(), True),\n",
    "            StructField(\"maintenance_date\", DateType(), True),\n",
    "            StructField(\"duration_minutes\", IntegerType(), True),\n",
    "            StructField(\"cost\", DecimalType(10, 2), True),\n",
    "            StructField(\"next_scheduled_date\", DateType(), True),\n",
    "            StructField(\"work_order_id\", StringType(), True),\n",
    "            StructField(\"safety_check_passed\", BooleanType(), True),\n",
    "            StructField(\"parts_list\", ArrayType(StringType()), True),\n",
    "            StructField(\"ingest_date\", DateType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    maintenance_data = [\n",
    "        # Ingest date 2025-04-28\n",
    "        (\n",
    "            \"MTN-001\",\n",
    "            \"MCH-001\",\n",
    "            \"preventive\",\n",
    "            datetime.strptime(\"2025-04-01\", \"%Y-%m-%d\").date(),\n",
    "            120,\n",
    "            Decimal(\"450.00\"),\n",
    "            datetime.strptime(\"2025-07-01\", \"%Y-%m-%d\").date(),\n",
    "            \"WO-001\",\n",
    "            True,\n",
    "            [\"filter\", \"gasket\"],\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"MTN-002\",\n",
    "            \"MCH-002\",\n",
    "            \"corrective\",\n",
    "            datetime.strptime(\"2025-04-15\", \"%Y-%m-%d\").date(),\n",
    "            240,\n",
    "            Decimal(\"1200.50\"),\n",
    "            datetime.strptime(\"2026-04-01\", \"%Y-%m-%d\").date(),\n",
    "            \"WO-002\",\n",
    "            False,\n",
    "            [\"motor\"],\n",
    "            datetime.strptime(\"2025-04-28\", \"%Y-%m-%d\").date(),\n",
    "        ),  # Future date issue\n",
    "        # Ingest date 2025-04-29\n",
    "        (\n",
    "            \"MTN-003\",\n",
    "            \"MCH-003\",\n",
    "            None,\n",
    "            datetime.strptime(\"2025-04-20\", \"%Y-%m-%d\").date(),\n",
    "            -30,\n",
    "            Decimal(\"-500.00\"),\n",
    "            datetime.strptime(\"2024-04-20\", \"%Y-%m-%d\").date(),\n",
    "            \"INVALID\",\n",
    "            None,\n",
    "            [],\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "        ),  # Multiple issues\n",
    "        (\n",
    "            \"MTN-004\",\n",
    "            \"MCH-001\",\n",
    "            \"predictive\",\n",
    "            datetime.strptime(\"2025-04-25\", \"%Y-%m-%d\").date(),\n",
    "            180,\n",
    "            Decimal(\"800.00\"),\n",
    "            datetime.strptime(\"2025-10-01\", \"%Y-%m-%d\").date(),\n",
    "            \"WO-003\",\n",
    "            True,\n",
    "            [\"sensor\"],\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        # Ingest date 2025-04-30\n",
    "        (\n",
    "            \"MTN-005\",\n",
    "            \"MCH-002\",\n",
    "            \"preventive\",\n",
    "            datetime.strptime(\"2025-04-29\", \"%Y-%m-%d\").date(),\n",
    "            90,\n",
    "            Decimal(\"300.00\"),\n",
    "            datetime.strptime(\"2025-07-15\", \"%Y-%m-%d\").date(),\n",
    "            \"WO-004\",\n",
    "            True,\n",
    "            [\"valve\"],\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "        (\n",
    "            \"MTN-006\",\n",
    "            \"MCH-003\",\n",
    "            \"corrective\",\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "            60,\n",
    "            Decimal(\"150.00\"),\n",
    "            datetime.strptime(\"2025-08-01\", \"%Y-%m-%d\").date(),\n",
    "            \"WO-005\",\n",
    "            False,\n",
    "            [\"pump\"],\n",
    "            datetime.strptime(\"2025-04-30\", \"%Y-%m-%d\").date(),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    maintenance_df = spark.createDataFrame(maintenance_data, schema=maintenance_schema)\n",
    "    maintenance_df.write.mode(\"overwrite\").saveAsTable(maintenance_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9391be33-3fd3-4004-85f8-9501332d965f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Understanding the datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67160e2d-6e18-4f78-9a0c-49c062d2da4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " \n",
    "### Machine Sensor Readings Dataset\n",
    "\n",
    "| Column Name        | Data Type    | Description                                      | Example Value         |\n",
    "|--------------------|-------------|--------------------------------------------------|----------------------|\n",
    "| `sensor_id`        | string      | Unique sensor identifier                         | SEN-001              |\n",
    "| `machine_id`       | string      | Linked machine identifier                        | MCH-001              |\n",
    "| `sensor_type`      | string      | Type of sensor (temperature, pressure, etc.)     | temperature          |\n",
    "| `reading_value`    | double      | Value recorded by the sensor                     | 72.4                 |\n",
    "| `reading_timestamp`| timestamp   | Time the reading was taken                       | 2025-04-28 14:32:00  |\n",
    "| `calibration_date` | date        | Last calibration date of the sensor              | 2025-04-01           |\n",
    "| `battery_level`    | int         | Battery percentage (0-100)                       | 85                   |\n",
    "| `facility_zone`    | string      | Plant zone or location                           | Zone-A               |\n",
    "| `is_active`        | boolean     | Whether the sensor is active                     | true                 |\n",
    "| `firmware_version` | string      | Sensor firmware version                          | v2.3.1               |\n",
    "| `ingest_date`      | date        | Date the record was ingested                     | 2025-04-28           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d96115a-cc94-45e2-8549-cef55cfffa46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Some sample \"Sensor Table\" Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f49e981f-b9bc-4891-9fc2-3805ef1977b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sensor Bronze Tables"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sensor_bronze_df = spark.read.table(sensor_table)\n",
    "print(\"=== Sensor Data Sample ===\")\n",
    "display(sensor_bronze_df.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24b1ef3f-a65c-412f-883c-de1fb1799cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "### Maintenance Records Dataset\n",
    "\n",
    "| Column Name           | Data Type        | Description                                   | Example Value           |\n",
    "|-----------------------|-----------------|-----------------------------------------------|------------------------|\n",
    "| `maintenance_id`      | string          | Unique maintenance event identifier           | MTN-001                |\n",
    "| `machine_id`          | string          | Linked machine identifier                     | MCH-001                |\n",
    "| `maintenance_type`    | string          | Type of maintenance (preventive, corrective)  | preventive             |\n",
    "| `maintenance_date`    | date            | Date maintenance was performed                | 2025-04-01             |\n",
    "| `duration_minutes`    | int             | Duration of maintenance in minutes            | 120                    |\n",
    "| `cost`                | decimal(10,2)   | Cost of maintenance                           | 450.00                 |\n",
    "| `next_scheduled_date` | date            | Next scheduled maintenance date               | 2025-07-01             |\n",
    "| `work_order_id`       | string          | Associated work order identifier              | WO-001                 |\n",
    "| `safety_check_passed` | boolean         | Whether safety check was passed               | true                   |\n",
    "| `parts_list`          | array   | List of parts replaced or serviced            | [\"filter\", \"gasket\"]   |\n",
    "| `ingest_date`         | date            | Date the record was ingested                  | 2025-04-28             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291e6b01-a363-469f-a45f-bb967901d7d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Some sample \"Maintenance Table\" Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcf3c3f0-ae97-4ad4-8d23-48613b5ac82c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mntnc_bronze_df = spark.read.table(maintenance_table)\n",
    "print(\"=== Maintenance Data Sample ===\")\n",
    "display(mntnc_bronze_df.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43877859-68ec-414d-84ee-9ea38e90bf5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Problem - Team doesn't know the Quality Rules for Maintenance Dataset\n",
    "### Feature - Infer the Data Quality Rules using DQX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b722aba-0bc6-436f-be33-c56a9731317a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Step-1**. Read Raw Data and Instantiate DQX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7afeb44f-c5f1-436e-a6aa-dc3ec7b8f405",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DQX Initialization"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.labs.dqx.profiler.profiler import DQProfiler\n",
    "from databricks.labs.dqx.profiler.generator import DQGenerator\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from pprint import pprint\n",
    "\n",
    "# Read Input Data\n",
    "mntnc_bronze_df = spark.read.table(maintenance_table)\n",
    "\n",
    "# Instantiate DQX engine\n",
    "ws = WorkspaceClient()\n",
    "dq_engine = DQEngine(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d1104ea-02b8-4d0d-9aef-15299cfce0f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Step-2**. Run DQX Profiler and **Infer** Quality Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6a16341-b7e7-4314-8b40-d71fe5cd6e3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Profile Inpute Data\n",
    "profiler = DQProfiler(ws)\n",
    "summary_stats, profiles = profiler.profile(mntnc_bronze_df)\n",
    "\n",
    "# Generate DQX quality rules/checks\n",
    "generator = DQGenerator(ws)\n",
    "checks = generator.generate_dq_rules(profiles)  # with default level \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b924099-c58d-4880-9828-8abf22f3c8c6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Review the Inferred checks"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== Inferred DQ Checks ===\")\n",
    "\n",
    "for idx, check in enumerate(checks):\n",
    "   print(f\"\\n========Check {idx} ==========\")\n",
    "   pprint(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f88207-e6a1-4e76-8f17-4290c3e10047",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save the quality rules in a file for review"
    }
   },
   "outputs": [],
   "source": [
    "# save checks in arbitrary workspace location\n",
    "maintenance_quality_rules = f\"{quality_rules_path}/maintenance_dq_rules.yml\"\n",
    "dq_engine.save_checks_in_workspace_file(checks, workspace_path=maintenance_quality_rules)\n",
    "\n",
    "# display the link to the saved checks\n",
    "displayHTML(f'<a href=\"/#workspace{maintenance_quality_rules}\" target=\"_blank\">Maintenance Data Quality Rules YAML</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2daca596-3bcf-4346-aa8b-e84f1595c3ce",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save the quality rules in delta table"
    }
   },
   "outputs": [],
   "source": [
    "# or save in delta table\n",
    "fq_tbl = f\"{database}.{schema}.maintenance_inferred_quality_rules\"\n",
    "dq_engine.save_checks_in_table(table_name=fq_tbl, checks=checks, run_config_name=\"maintenance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c09956cd-142f-40c8-9bc4-5a101b083845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Step-3**. Apply Inferred Quality Rules to Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab3f55f9-128d-4cb6-a34c-aa707b302b78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load checks from workspace file\n",
    "quality_checks = dq_engine.load_checks_from_workspace_file(workspace_path=maintenance_quality_rules)\n",
    "# or Load checks from a table\n",
    "# quality_checks = dq_engine.load_checks_from_table(table_name=fq_tbl, run_config_name=\"maintenance\")\n",
    "\n",
    "# Apply checks on input data\n",
    "valid_df, quarantined_df = dq_engine.apply_checks_by_metadata_and_split(mntnc_bronze_df, quality_checks)\n",
    "\n",
    "print(\"=== Maintenance Bad Data Sample ===\")\n",
    "display(quarantined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d02d33c9-ab68-4151-9a2b-b4e3791c1cc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Data Quality Rules for Machine Sensor Data\n",
    "\n",
    "| Rule Type             | Example Rule                                                                                           | Purpose / Impact                                                        |DQ Rule|Quality Error Level|\n",
    "|-----------------------|-------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|-|--|\n",
    "| **Completeness**      | Required fields (`sensor_id`, `machine_id`) must not be null    | Ensures all critical data is present and usable     |`is_not_null_and_not_empty`                    |ERROR|\n",
    "| **Range / Domain**    | `reading_value` (temperature): 0–100 | Detects outliers and sensor faults; ensures physical plausibility       |**FILTER quality Check + `is_in_range`**| WARN|\n",
    "| **Format Standardization**  |  `machine_id` follows standard format                             | Standardizes data for integration and analysis                          |`regex_match` |WARN|\n",
    "| **Timeliness**        | `reading_timestamp` is not in the future; beyond 3 days                                     | Prevents erroneous time-series data                            |`is_not_in_future` |ERROR|\n",
    "| **Correctness**        | `calibration_date` is eariler than `reading_timestamp`| Prevents erroneous sesnor readings data                            |`SQL Expression` |ERROR|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dfc8cfd-1e9d-4490-86e6-d4c7138a3dc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature: Quality Rules as YAML \n",
    "Read quality rules from the a YAML file and apply checks on a Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "775bf506-1a98-440a-9a3f-9448eae640fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Apply DQ Rules on Sensor Dataset"
    }
   },
   "outputs": [],
   "source": [
    "sensor_bronze_df = spark.read.table(sensor_table)\n",
    "sensor_quality_checks = dq_engine.load_checks_from_workspace_file(workspace_path=f\"{quality_rules_path}/sensor_dq_rules.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3ab0ee-125a-4ad0-8bc5-621048bc33a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Features: Quarantine Bad Data & Perform Granular Issue Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc0ec47-488c-41bc-8806-8fea01353836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "valid_df, quarantined_df = dq_engine.apply_checks_by_metadata_and_split(sensor_bronze_df, sensor_quality_checks)\n",
    "\n",
    "print(\"=== Bad Data DF ===\")\n",
    "display(quarantined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e54ef9c7-03b4-4dad-8bad-9385beb8a609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature: Bring / Build Your own Rule (Check)\n",
    "|Dataset| Rule Type             | Example Rule                                                                                           | Purpose / Impact                                                        |DQ Rule|\n",
    "|-|-----------------------|-------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|--|\n",
    "|Sensor Data| **Standardization**          | `firmware_version` starts with \"v\"  | Ensures firmware version value is a standard value | Custom Rule Development| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70f9cbd1-a9e8-442a-9269-be4447066b41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Column as col\n",
    "from databricks.labs.dqx.check_funcs import make_condition\n",
    "\n",
    "def firmware_version_start_with_v(column: str) -> col:\n",
    "    column_expr = F.expr(column)\n",
    "    \n",
    "    quality_rule_expr = ~(column_expr.startswith(\"v\"))\n",
    "    quality_rule_err_msg = f\"firmware_version doesn't starts with 'v'\"\n",
    "    quality_rule_err_col_name = f\"firmware_version_not_starts_with_v\"\n",
    "\n",
    "    return make_condition(quality_rule_expr, quality_rule_err_msg, quality_rule_err_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2404ff07-b9b7-4974-8a7e-acdce35c5e03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Feature : YAML Way\n",
    "\n",
    "[Sensor Data Quality Custom Rules YAML](https://e2-demo-field-eng.cloud.databricks.com/editor/files/2408509664666985?o=1444828305810485)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0763314b-c46e-457a-ba08-45d01d7451f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Step-1** Read the input data and instantiate DQX Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb3ad64-ef8c-4e5c-8270-088b61c70b1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sensor_bronze_df = spark.read.table(sensor_table)\n",
    "sensor_quality_checks = dq_engine.load_checks_from_workspace_file(\n",
    "    workspace_path=f\"{quality_rules_path}/sensor_dq_rules_custom.yml\")\n",
    "\n",
    "dq_engine = DQEngine(WorkspaceClient())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd7b730d-8ec8-45e3-aa33-f9018d3ccd70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the custom check \n",
    "custom_check_functions = {\"firmware_version_start_with_v\": firmware_version_start_with_v}  # list of custom check functions\n",
    "\n",
    "# Apply the custom check on the bronze data\n",
    "valid_df, quarantined_df = dq_engine.apply_checks_by_metadata_and_split(sensor_bronze_df, sensor_quality_checks, custom_check_functions)\n",
    "display(quarantined_df)\n",
    "\n",
    "sensor_quarantine_table = f\"{database}.{schema}.sensor_quarantine\"\n",
    "quarantined_df.write.mode(\"overwrite\").saveAsTable(sensor_quarantine_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebc2bfa8-754b-4b94-950e-188033e0470c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature: Visualize Quality on Pre-Configured Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e82950d5-c1fd-4665-bccb-6a73bd84dd2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "https://e2-demo-field-eng.cloud.databricks.com/dashboardsv3/01f025eecf261a81996b8991df9e870b/published?o=1444828305810485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bb9b5cb-9ada-4609-9cce-402d3d82706d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![dashboard.png](./images/dashboard.png \"dashboard.png\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3878688999317734,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "dqx-mfg-demo-dais",
   "widgets": {
    "demo_database": {
     "currentValue": "amitabh_arora_catalog",
     "nuid": "09b06c51-5423-4220-ae98-e015bddd699d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "main",
      "label": "Catalog Name",
      "name": "demo_database",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "main",
      "label": "Catalog Name",
      "name": "demo_database",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "demo_schema": {
     "currentValue": "dqx_demo",
     "nuid": "b66ea58c-8c7c-447c-bf6f-9e0163913e90",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "demo_schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default",
      "label": "Schema Name",
      "name": "demo_schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
